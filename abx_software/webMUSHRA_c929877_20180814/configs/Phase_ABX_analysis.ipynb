{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Evaluation of ABX Test with webMUSHRA\n",
    "\n",
    "\n",
    "Below we read the csv-data of the [webMUSHRA](https://github.com/audiolabs/webMUSHRA) based ABX-test and analyze the data in terms of binomial and $\\chi^2$ statistics\n",
    "\n",
    "We used [GPower3](http://www.gpower.hhu.de/) to configure the ABX test design, see\n",
    "Faul, F., Erdfelder, E., Lang, A.-G., & Buchner, A. (2007). *GPower 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences*. Behavior Research Methods, **39**, 175-191\n",
    "\n",
    "VP...Versuchsperson, i.e. test subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import binom, chi2, chisquare, chi2_contingency\n",
    "\n",
    "def calc_p(correct_trials, total_trials):\n",
    "    # return probability of at least 'correct_trials' out of 'total_trials'\n",
    "    # with 50:50 chance coin flipping\n",
    "    return 1-binom.cdf(correct_trials-1, total_trials, 0.5)\n",
    "\n",
    "def print_quartiles(tmp, unit=' '):  # some basic statistics \n",
    "    # tmp = 1 * np.random.randn(1, 100000) + 0\n",
    "    print('mean: %3.1f'% np.mean(tmp), unit)\n",
    "    print('std : %3.1f'% np.std(tmp, ddof=1), unit)\n",
    "    print('percentiles:')\n",
    "    print('P5  : %3.1f'% np.quantile(tmp, .05), unit)\n",
    "    print('P25 : %3.1f'% np.quantile(tmp, .25), unit)\n",
    "    print('P50 : %3.1f'% np.quantile(tmp, .5), unit)\n",
    "    print('P75 : %3.1f'% np.quantile(tmp, .75), unit)\n",
    "    print('P95 : %3.1f'% np.quantile(tmp, .95), unit)\n",
    "    print('IQR : %3.1f'% (np.quantile(tmp, .75) - np.quantile(tmp, .25)), unit)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Characteristics for 5 Audio Files Repeated Measures"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G*Power 3.1 protocol:\n",
    "Exact - Proportion: Difference from constant (binomial test, one sample case)\n",
    "Analysis:\tA priori: Compute required sample size \n",
    "Input:\t\tTail(s)                  \t=\tOne\n",
    "\t\t\tEffect size g            \t=\t0,4\n",
    "\t\t\tα err prob               \t=\t0,01\n",
    "\t\t\tPower (1-β err prob)     \t=\t0,99\n",
    "\t\t\tConstant proportion      \t=\t0,5\n",
    "Output:\t\tLower critical N         \t=\t19,0000000\n",
    "\t\t\tUpper critical N         \t=\t19,0000000\n",
    "\t\t\tTotal sample size        \t=\t25\n",
    "\t\t\tActual power             \t=\t0,9905236\n",
    "\t\t\tActual α                 \t=\t0,007316649\n",
    "\n",
    "g = 0.4, i.e. 90% detection rate was set up from pretests (e.g. square wave burst: -45deg 24/28 = 0.857 detection ratio, -90deg 27/28 = 0.964 detection ratio, (0.85+0.95)/2 = 0.9 -> g = 0.4)\n",
    "\n",
    "Bonferroni correction for 5 different audio materials -> a final = 0.05, 1-b final = 0.95 desired\n",
    "leading to 25*5 = 125 trials in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0.05/5, 1-0.05/5)\n",
    "print(19/25)\n",
    "print(25*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Characteristics for Single Audio File, Very Small Effect Size\n",
    "\n",
    "Single audio with about same number of total trials 119 (vs. 25*5=125 from five stimuli), leading to decreased (for certain stimuli probably more realistic) effect size:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G*Power 3.1 protocol:\n",
    "Exact - Proportion: Difference from constant (binomial test, one sample case)\n",
    "Analysis:\tA priori: Compute required sample size \n",
    "Input:\t\tTail(s)                  \t=\tOne\n",
    "\t\t\tEffect size g            \t=\t0,15\n",
    "\t\t\tα err prob               \t=\t0,05\n",
    "\t\t\tPower (1-β err prob)     \t=\t0,95\n",
    "\t\t\tConstant proportion      \t=\t0,5\n",
    "Output:\t\tLower critical N         \t=\t69,0000000\n",
    "\t\t\tUpper critical N         \t=\t69,0000000\n",
    "\t\t\tTotal sample size        \t=\t119\n",
    "\t\t\tActual power             \t=\t0,9540704\n",
    "\t\t\tActual α                 \t=\t0,0492618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Characteristics for Single Audio File, 18/26 Trials\n",
    "\n",
    "If only a single audio was to be evaluated by a single VP with 25 trials as above, we consider **26** trials yielding decreased effect size of 0.31 for an alpha = 0.05 and 1-beta about 0.95.\n",
    "\n",
    "Or: g=0.3 results in 1-b = 0.89 for 18/25 trials"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G*Power 3.1 protocol:\n",
    "Exact - Proportion: Difference from constant (binomial test, one sample case)\n",
    "Analysis:\tA priori: Compute required sample size \n",
    "Input:\t\tTail(s)                  \t=\tOne\n",
    "\t\t\tEffect size g            \t=\t0,31\n",
    "\t\t\tα err prob               \t=\t0,05\n",
    "\t\t\tPower (1-β err prob)     \t=\t0,95\n",
    "\t\t\tConstant proportion      \t=\t0,5\n",
    "Output:\t\tLower critical N         \t=\t18,0000000\n",
    "\t\t\tUpper critical N         \t=\t18,0000000\n",
    "\t\t\tTotal sample size        \t=\t26\n",
    "\t\t\tActual power             \t=\t0,9554834\n",
    "\t\t\tActual α                 \t=\t0,0377593\n",
    "            \n",
    "Analysis:\tPost hoc: Compute achieved power \n",
    "Input:\t\tTail(s)                  \t=\tOne\n",
    "\t\t\tEffect size g            \t=\t0,3\n",
    "\t\t\tα err prob               \t=\t0,05\n",
    "\t\t\tTotal sample size        \t=\t25\n",
    "\t\t\tConstant proportion      \t=\t0,5\n",
    "Output:\t\tLower critical N         \t=\t18,0000000\n",
    "\t\t\tUpper critical N         \t=\t18,0000000\n",
    "\t\t\tPower (1-β err prob)     \t=\t0,8908772\n",
    "\t\t\tActual α                 \t=\t0,0216426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(18/26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: in csv the trial_id suffix must be between\n",
    "# 0...9 for test part and 00..99 for trial number \n",
    "suffix_length = 5  # if audio is 'hotel', trial_id is denoted with\n",
    "# e.g. 'hotel_2_01' for part 2, stimulus 01 \n",
    "csvfile = '../results/abx_constant_phase_shift/paired_comparison.csv'\n",
    "audio = ['square_a',\n",
    "         'square_b',\n",
    "         'pnoise',\n",
    "         'castanets',\n",
    "         'hotelcalifornia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Sorted Dictionaries\n",
    "\n",
    "To make things more accessible we sort and write help csv-files first.\n",
    "\n",
    "We also count the number of VP here in the first sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VP = 0  # init as cleared\n",
    "with open(csvfile, newline='') as f:\n",
    "    dr = csv.DictReader(f, delimiter=\",\")\n",
    "    sorted_vp_id = sorted(dr, key=lambda row:(row['vp_id'], row['trial_id'], row['choice_answer']),\n",
    "                          reverse=False)\n",
    "with open('../results/abx_constant_phase_shift/sorted_vp_id.csv', 'w+') as f:\n",
    "    fieldnames = ['vp_id', 'trial_id', 'choice_answer',\n",
    "                  'age', 'gender', 'choice_reference', 'choice_non_reference',\n",
    "                  'session_test_id', 'choice_time', 'choice_comment']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in sorted_vp_id:\n",
    "        writer.writerow(row)\n",
    "        if int(row['vp_id']) > VP:\n",
    "            VP = int(row['vp_id'])  # 'count' VP\n",
    "        \n",
    "with open(csvfile,newline='') as f:\n",
    "    dr = csv.DictReader(f, delimiter=\",\")\n",
    "    sorted_trial_id = sorted(dr, key=lambda row:(row['trial_id'], row['choice_answer'], row['vp_id']),\n",
    "                             reverse=False)\n",
    "with open('../results/abx_constant_phase_shift/sorted_trial_id.csv', 'w+') as f:\n",
    "    fieldnames = ['trial_id', 'choice_answer', 'vp_id',\n",
    "                  'age', 'gender', 'choice_reference', 'choice_non_reference',\n",
    "                  'session_test_id', 'choice_time', 'choice_comment']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in sorted_trial_id:\n",
    "        writer.writerow(row)\n",
    "\n",
    "VP = VP+1 # number of in listening test persons, in csv encoded as vp_id = 0...VP-1\n",
    "print('total VPs =',VP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics: Age in Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.zeros((VP, 1), dtype=np.uint)\n",
    "for vp in range(0, VP):\n",
    "    for row in sorted_vp_id:\n",
    "        if int(row['vp_id']) == vp:\n",
    "            age[vp] = int(row['age'])\n",
    "            break\n",
    "print_quartiles(age, unit='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics: Trial Decision in Seconds for all VP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros((VP*25,5))\n",
    "for ai, a in enumerate(audio):  # for all audio\n",
    "    print('audio:', a)\n",
    "    tmp = np.empty(0)\n",
    "    for row in sorted_trial_id:\n",
    "        if row['trial_id'][0:-suffix_length] == a:\n",
    "            tmp = np.append(tmp, int(row['choice_time']))\n",
    "    print('total time %3.1f' % (np.sum(tmp)/1000/60), 'min')\n",
    "    # note: the recorded time might include longer rests that VP took while rating!\n",
    "    # however, we might assume that these breaks were equally distributed over the\n",
    "    # trials, so the median and IQR should give a fair picture of rating times\n",
    "    print_quartiles(tmp/1000, unit='s')\n",
    "    t[:,ai] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianprops = dict(linestyle='-', linewidth=3, color='C0')\n",
    "boxprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "flierprops = dict(marker='P', markerfacecolor='C0',\n",
    "                  markeredgecolor='C0',\n",
    "                  markersize=4,\n",
    "                  linestyle='none')\n",
    "plt.boxplot(t/1000, whis=[5,95], labels=audio, widths=0.75,\n",
    "            medianprops=medianprops,\n",
    "            boxprops=boxprops,\n",
    "            flierprops=flierprops);\n",
    "plt.ylim(0,150)\n",
    "plt.yticks(np.arange(0,160,10))\n",
    "plt.ylabel('trial decision time in seconds')\n",
    "plt.title(r'median P$_{50}$, box P$_{25}$ & P$_{75}$, whisker P$_{5}$ & P$_{95}$')\n",
    "plt.grid(True);\n",
    "plt.savefig('boxplot_time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matrix [VP x Audio]\n",
    "\n",
    "* total trials\n",
    "* correct trials\n",
    "* incorrect trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = np.zeros((VP, len(audio)), dtype=np.uint)\n",
    "x_correct = np.zeros((VP, len(audio)), dtype=np.uint)\n",
    "x_incorrect = np.zeros((VP, len(audio)), dtype=np.uint)\n",
    "for vp in range(0, VP):  # for all participants\n",
    "    for ai, a in enumerate(audio):  # for all audio\n",
    "        for row in sorted_vp_id:  # through data\n",
    "            if (int(row['vp_id']) == vp) and (row['trial_id'][0:-suffix_length] == a):\n",
    "                # data match:\n",
    "                x_total[vp, ai]+= 1\n",
    "                if row['choice_answer'] == 'correct':\n",
    "                    x_correct[vp, ai]+= 1\n",
    "                elif row['choice_answer'] == 'incorrect':\n",
    "                    x_incorrect[vp, ai]+= 1\n",
    "if False:  # test data\n",
    "    x_correct[0,0] = 10  # p = 0.019287109375\n",
    "    x_incorrect[0,0] = 2\n",
    "    x_total[0,0] = 12\n",
    "    x_correct[7,3] = 7  # p = 0.03515625\n",
    "    x_incorrect[7,3] = 1\n",
    "    x_total[7,3] = 8\n",
    "    x_correct[2,2] = 98  # p = 0.04705736150777151\n",
    "    x_incorrect[2,2] = 173-98\n",
    "    x_total[2,2] = 173\n",
    "\n",
    "if (x_total==0).any() and True:\n",
    "    print('!!! warning !!! check: x_total is zero somewhere')\n",
    "    print('x_total==0 should not happen (i.e. all False is required):\\n', x_total==0)\n",
    "    \n",
    "if np.max(np.abs(x_total - x_correct - x_incorrect)) != 0:\n",
    "    print('!!! warning !!! check: x_total != x_correct + x_incorrect results')\n",
    "\n",
    "if VP*5*25!=np.sum(x_total):\n",
    "    print('!!! warning !!! missing data, check that all VP performed all parts')\n",
    "\n",
    "print(x_total)\n",
    "    \n",
    "print()\n",
    "\n",
    "if False:\n",
    "    print('audio:\\n', audio)\n",
    "    print('x_total:\\n', x_total)\n",
    "    print('x_correct:\\n', x_correct)\n",
    "    print('x_incorrect:\\n', x_incorrect)\n",
    "    print()\n",
    "\n",
    "# per audio:\n",
    "idx = 0\n",
    "print('all vp per', audio[idx], ': total', np.sum(x_total[:,idx]),\n",
    "      ', correct', np.sum(x_correct[:,idx]),\n",
    "      ', incorrect', np.sum(x_incorrect[:,idx]), ', p = %4.3f' %\n",
    "      calc_p(np.sum(x_correct[:,idx]), np.sum(x_total[:,idx])))\n",
    "\n",
    "# per vp:\n",
    "idx = 0\n",
    "print('all audio per vp', idx, ': total', np.sum(x_total[idx,:]),\n",
    "      ', correct', np.sum(x_correct[idx,:]),\n",
    "      ', incorrect', np.sum(x_incorrect[idx,:]), ', p = %4.3f' %\n",
    "      calc_p(np.sum(x_correct[idx,:]), np.sum(x_total[idx,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Individual Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = calc_p(x_correct, x_total)\n",
    "pb = p<0.01\n",
    "h = x_correct / x_total * 100  # detection frequency correct answers / Häufigkeit \n",
    "np.set_printoptions(precision=1, suppress=True)\n",
    "print('audio:\\n', audio)\n",
    "print('detection rate in % :\\n', h)\n",
    "#print('pbinom = \\n', p)\n",
    "print('pbinom < 1% = (i.e. we may reject H0, i.e. guessing is very unlikely, ')\n",
    "print('i.e. it is very unlikely that our data stems from the H0 PDF(50:50 chance)):\\n', pb)\n",
    "np.set_printoptions(precision=8, suppress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD: dynamic alloc wrt len(audio)\n",
    "data_dict = {0: list(h[:,0]), 1: list(h[:,1]), 2: list(h[:,2]), 3: list(h[:,3]), 4: list(h[:,4])}\n",
    "\n",
    "alabel = audio.copy()\n",
    "for (c, v) in enumerate(alabel):\n",
    "    if v == 'square_a':\n",
    "        alabel[c] = 'square -90°'\n",
    "    if v == 'square_b':\n",
    "        alabel[c] = 'square -45°'  \n",
    "    if v == 'pnoise':\n",
    "        alabel[c] = 'pink noise -90°'  \n",
    "    if v == 'hotelcalifornia':\n",
    "        alabel[c] = 'hotel cal -90°'\n",
    "    if v == 'castanets':\n",
    "        alabel[c] = 'castanets -90°'        \n",
    "\n",
    "fig = plt.figure()    \n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# 19/25 hardcoded:\n",
    "plt.plot([-1, len(audio)],[19/25*100, 19/25*100], \n",
    "         '-.', color='k', lw=2, label=r'$H_0$ rejection border, 19 correct of 25 trials, i.e. 76%', zorder=1)\n",
    "plt.plot([-1, len(audio)], [50, 50], '-', color='k', lw=1, label=r'$H_0(p=0.5)$, i.e. guessing 50%', zorder=1)\n",
    "size_constant = 30\n",
    "for xe, ye in data_dict.items():\n",
    "    xAxis = [xe] * len(ye)\n",
    "    sizes = [ye.count(num)**1.66 * size_constant for num in ye]\n",
    "    counter = [ye.count(num) for num in ye]\n",
    "    plt.scatter(xAxis, ye, s=sizes, color='C0',zorder=3)\n",
    "    for c, v in enumerate(counter):  # annotate totals>1 as text\n",
    "        if v > 1:\n",
    "            plt.text(xe-0.03, ye[c]-1, v,color='w')\n",
    "plt.xticks(np.arange(0,len(audio)), [alabel[0], alabel[1], alabel[2], alabel[3], alabel[4]])\n",
    "ty = np.round(np.arange(5,26)/25*100, 1)  # y ticks, 25 hardcoded!\n",
    "tys = ty.astype(str)  # y ticks label as strings\n",
    "tys[1::2] = ' '  # only each second string\n",
    "plt.yticks(ty, tys)\n",
    "plt.xlim(-0.15,len(audio)-1+0.15)\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.xlabel('stimulus')\n",
    "plt.ylabel('correct answers in %')\n",
    "plt.title(r'effect size g=0.4, $\\alpha=0.01$, power $1-\\beta=0.99$, $N=25$, $N_\\mathrm{crit}=19$')\n",
    "plt.legend(loc=3);\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ty = np.arange(0,22)  # y ticks, hack!!!\n",
    "tys = (ty+5).astype(str)  # y ticks label as strings\n",
    "tys[1::2] = ' '  # only each second string\n",
    "plt.yticks(ty, tys)\n",
    "plt.ylabel('number of correct answers');\n",
    "\n",
    "plt.savefig('scatter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi2 Tests Single Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # manual calc for audio[0]:\n",
    "    idx = 0\n",
    "    total = sum(x_total)[idx]  # total answers\n",
    "    expect = total*0.5 # 50:50\n",
    "    incorrect = sum(x_incorrect)[idx]  # incorrect answers\n",
    "    correct = sum(x_correct)[idx]  # correct asnwers\n",
    "    chisq = ((correct-expect)**2 / expect) + ((incorrect-expect)**2 / expect)\n",
    "    p = 1 - chi2.cdf(chisq, df=1)\n",
    "    print('audio:', audio[idx])\n",
    "    print('incorrect %4.3f' % (incorrect/total), ', correct %4.3f' % (correct/total))\n",
    "    print(chisquare([correct, incorrect]))\n",
    "    print('chi2 = %4.3f'% chisq, ', p = %4.3f'% p, ', p<0.01', p<0.05)\n",
    "    print()\n",
    "\n",
    "#doing all audio with chisquare():\n",
    "for (c,v) in enumerate(audio):\n",
    "    print('audio:', v)\n",
    "    print('correct answers:', sum(x_correct)[c], 'incorrect answers', sum(x_incorrect)[c])\n",
    "    chisq, p = chisquare([sum(x_correct)[c], sum(x_incorrect)[c]])\n",
    "    print('chi2 = %4.3f'% chisq, ', p = %4.3f'% p, ', p<0.01', p<0.01)\n",
    "    if p<0.01:\n",
    "        print('reject H0, frequency of correct and incorrect answers is different')\n",
    "        print('indicates NO guessing')\n",
    "    else:\n",
    "        print('H0 might not be rejected, frequency of correct and incorrect answers is about the same')\n",
    "        print('indicates guessing')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi2 Tests Pairwise Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful stuff: http://www.biostathandbook.com/chiind.html\n",
    "if False:\n",
    "    f_obs = np.array([[8177, 8147], [575, 555]]).T  # Selenium vs. Selenium+E\n",
    "    chisq, p, df, ex = chi2_contingency(f_obs, correction=False)\n",
    "    print('chi2 = %4.3f' % chisq, ', p = %4.3f'% p, ', p<0.05', p<0.05)\n",
    "    chi2_contingency(f_obs, correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "cnt = 0\n",
    "n_of_pairs = 10\n",
    "for i in range(0,len(audio)):  # find all unique pairs\n",
    "    for j in range(i,len(audio)): \n",
    "        if i!=j:\n",
    "            print('pair', cnt, ':', audio[i], 'vs.', audio[j])  # unique pair\n",
    "            cnt += 1\n",
    "            obs = [[sum(x_correct)[i], sum(x_correct)[j]], [sum(x_incorrect)[i], sum(x_incorrect)[j]]]\n",
    "            chisq, p, df, ex = chi2_contingency(obs, correction=False)\n",
    "            print('df =', df, ', chi2 = %4.3f'% chisq, ', p = %4.3f'% p, ', reject H0:', p<0.05/n_of_pairs)\n",
    "\n",
    "            # print(obs)\n",
    "            # print('corr1 =', obs[0][0], 'corr2 =', obs[1][0], 'incorr1 =', obs[0][1], 'incorr2 =', obs[1][1])\n",
    "            corr1 = obs[0][0]\n",
    "            corr2 = obs[1][0]\n",
    "            incorr1 = obs[0][1]\n",
    "            incorr2 = obs[1][1]\n",
    "            total1 = corr1 + incorr1\n",
    "            total2 = corr2 + incorr2\n",
    "            OR = (corr1/incorr1) / (corr2/incorr2)\n",
    "            RR = (corr1/total1) / (corr2/total2)\n",
    "            print('odds ratio (OR):',  OR, ', risk ratio (RR):', RR)\n",
    "\n",
    "            # alpha correction for 10 pairwise comparisons\n",
    "            if p<0.05/n_of_pairs:\n",
    "                print('reject H0, variables are rather independent, indicates different rating')\n",
    "            else:\n",
    "                print('H0 might not be rejected, indicates similar rating')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we might not need the stuff below anymore...\n",
    "\n",
    "## all vp per audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all vp per audio:\\n')\n",
    "for a in audio:\n",
    "    print('audio:', a)\n",
    "    total_trials, correct_trials, incorrect_trials = 0, 0, 0\n",
    "    for row in sorted_trial_id:\n",
    "        if row['trial_id'][0:-suffix_length] == a:\n",
    "            total_trials+= 1\n",
    "            if row['choice_answer'] == 'correct':\n",
    "                correct_trials+= 1   \n",
    "            elif row['choice_answer'] == 'incorrect':\n",
    "                incorrect_trials+= 1\n",
    "    if total_trials - correct_trials - incorrect_trials == 0: \n",
    "        print('trials: total', total_trials,\n",
    "              ', correct', correct_trials,\n",
    "              ', incorrect', incorrect_trials)\n",
    "        p = calc_p(correct_trials, total_trials)\n",
    "        print('p = %4.3f' % p)\n",
    "        if p<0.05:\n",
    "            print('H0 may be rejected, i.e. guessing is very unlikely')\n",
    "    else:\n",
    "        print('total trials not equal to correct+incorrect trials')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all audio per vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all audio per vp:\\n')\n",
    "for vp in range(0, VP):\n",
    "    print('VP:', vp)\n",
    "    total_trials, correct_trials, incorrect_trials = 0, 0, 0\n",
    "    for row in sorted_vp_id:\n",
    "        if int(row['vp_id']) == vp:\n",
    "            total_trials+= 1\n",
    "            if row['choice_answer'] == 'correct':\n",
    "                correct_trials+= 1   \n",
    "            elif row['choice_answer'] == 'incorrect':\n",
    "                incorrect_trials+= 1\n",
    "    if total_trials - correct_trials - incorrect_trials == 0: \n",
    "        print('trials: total', total_trials,\n",
    "              ', correct', correct_trials,\n",
    "              ', incorrect', incorrect_trials)\n",
    "        p = calc_p(correct_trials, total_trials)\n",
    "        print('p = %4.3f' % p)\n",
    "        if p<0.05:\n",
    "            print('H0 may be rejected, i.e. guessing is very unlikely')\n",
    "    else:\n",
    "        print('check: x_total != x_correct + x_incorrect results')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    suffix_length = 3\n",
    "    print('all vp per audio:\\n')\n",
    "    for part in range(0,4):\n",
    "        print('### part', part)\n",
    "        for a in audio:\n",
    "            print('audio:', a)\n",
    "            total_trials, correct_trials, incorrect_trials = 0, 0, 0\n",
    "            for row in sorted_trial_id:\n",
    "                if row['trial_id'][0:-suffix_length] == a+'_'+str(part):\n",
    "                    total_trials+= 1\n",
    "                    if row['choice_answer'] == 'correct':\n",
    "                        correct_trials+= 1   \n",
    "                    elif row['choice_answer'] == 'incorrect':\n",
    "                        incorrect_trials+= 1\n",
    "            if total_trials - correct_trials - incorrect_trials == 0: \n",
    "                print('trials: total', total_trials,\n",
    "                      ', correct', correct_trials,\n",
    "                      ', incorrect', incorrect_trials)\n",
    "                p = calc_p(correct_trials, total_trials)\n",
    "                print('p =',p)\n",
    "                #if p<0.05:\n",
    "                #    print('H0 may be rejected, i.e. guessing is very unlikely')\n",
    "            else:\n",
    "                tmp = 0\n",
    "                #print('total trials not equal to correct+incorrect trials')\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
